{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the IGM documentation Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Welcome to the IGM documentation"},{"location":"#welcome-to-the-igm-documentation","text":"","title":"Welcome to the IGM documentation"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"1.-Installation/","text":"IGM is a Python package, which works on any OS on CPU (not computationally efficient, but fine for small applications like individual glaciers), GPU (the most computationally efficient way, especially relevant for large-scale and high-resolution applications). IGM can be installed with the the main version for stable application (the latest available tag), not all modules, the development version to get the latest feature with all modules (at the possible price of unrevealed bugs). Both versions are now on the same (main) branch. IGM is rapidly changing, keep track of updates on the release page for the tagged versions or/and on this page for the development version. Note that the igm package installs most of dependent packages, but not all. For using some post-processing modules, the user has to install additional packages (e.g., mayavi, plotly, ect.). We first describe the installation in Linux (the preferred OS), and then on Windows and Mac. Linux Install NVIDIA drivers If you aim to use only the CPU or already get an output from nvidia-smi , you can skip this step. # get the latest libraries from apt sudo apt update sudo apt upgrade # choose which driver version is compatible with your GPU device (in this case 510) sudo apt install nvidia-driver-510 nvidia-dkms-510 sudo reboot # you wont see the changes until after you reboot After rebooting, you can check your driver version with the command watch -d -n 0.5 nvidia-smi should give you live information on your GPU device. Install anaconda and create a virtual environment (strongly recommended) with conda or venv: # install anaconda wget https://repo.anaconda.com/archive/Anaconda3-2023.09-0-Linux-x86_64.sh bash Anaconda3-2023.09-0-Linux-x86_64.sh # create new environment conda create --name igm python=3.10 # activate environment to install IGM conda activate igm or # create igm venv environment python3.10 -m venv igm # activate environment to install IGM source igm/bin/activate Install IGM For simple usage, you can install the latest IGM stable version and its dependencies from the Pypi as follows: pip install igm_model OR for using all and recent features, you can install the IGM development version from the github repository as follows: git clone https://github.com/jouvetg/igm.git cd igm pip install -e . After that, you may run any example ( igm_run ). As IGM is being updated often, make sure you have the latest version, you may run git pull Windows Tensorflow does not allow us to run IGM on GPU directly on Windows, and the module oggm_shop does not work on windows. Therefore, we recommend windows-user to install WSL2-ubuntu, which provides a linux/ubuntu terminal. WSL2 terminal can be nicely linked with VS code (with an extension). First, install WSL2-ubuntu wsl --install Ubuntu-22.04 sudo apt update sudo apt upgrade and then, install the NVIDIA drivers if not done (if you get no output from nvidia-smi ), and if you wish to use the GPU. The rest -- installation of conda or venv environment and the installation of IGM -- are the same as above on Linux. Mac IGM core library native Tensorflow is not supported on Mac for GPU usage. Instead, a \"Tensorflow for Mac\", called tensorflow-metal , was developed as workaround. To install IGM on Mac, you may follow the linux workflow, however, you will need to change in setup.py tensorflow by tensorflow-macos. Here is a working procedure (tested on MacBook Pro M2) -- still we recommend using a virtual environment such as conda or venv as on linux: git clone -b develop https://github.com/jouvetg/igm cd igm You need to edit \"install_requires=[...]\" in the file \"setup.py\": To use only the CPUs: tensorflow-macos==2.14.0 To use the GPUs: tensorflow-macos==2.14.0, tensorflow-metal, and then pip install -e . Troubleshooting Main source of issues are linked to Tensorflow and the use of GPU. Hopefully, the installation is significantly easier since tensorflow 2.14.0 since it can install all necessary GPU/cuda dependent packages with the right version automatically. Note that to ensure smooth usage of GPU with cuda and tensorflow libraries , one has to make sure that i) cuda ii) cudnn iii) tensorflow are compatible , and your Nvidia driver is compatible with the version of cuda. Such incompatibility is the most common source of issue. For instance, it is possible do install tensorflow-2.12.0 by setting tensorflow==2.12.0 in the setup.py and conda install -c conda-forge cudatoolkit=11.8.0 pip install nvidia-cudnn-cu11==8.6.0.163 mkdir -p ${CONDA_PREFIX}/etc/conda/activate.d D=${CONDA_PREFIX}/etc/conda/activate.d/env.sh echo 'export PYTHONNOUSERSITE=1' >> $D echo 'export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${CONDA_PREFIX}/lib' >> $D echo 'export CUDNN_PATH=$(dirname $(python -c \"import nvidia.cudnn;print(nvidia.cudnn.__file__)\"))' >> $D echo 'export LD_LIBRARY_PATH=$CONDA_PREFIX/lib/:$CUDNN_PATH/lib:$LD_LIBRARY_PATH' >> $D","title":"1. Installation"},{"location":"1.-Installation/#linux","text":"Install NVIDIA drivers If you aim to use only the CPU or already get an output from nvidia-smi , you can skip this step. # get the latest libraries from apt sudo apt update sudo apt upgrade # choose which driver version is compatible with your GPU device (in this case 510) sudo apt install nvidia-driver-510 nvidia-dkms-510 sudo reboot # you wont see the changes until after you reboot After rebooting, you can check your driver version with the command watch -d -n 0.5 nvidia-smi should give you live information on your GPU device. Install anaconda and create a virtual environment (strongly recommended) with conda or venv: # install anaconda wget https://repo.anaconda.com/archive/Anaconda3-2023.09-0-Linux-x86_64.sh bash Anaconda3-2023.09-0-Linux-x86_64.sh # create new environment conda create --name igm python=3.10 # activate environment to install IGM conda activate igm or # create igm venv environment python3.10 -m venv igm # activate environment to install IGM source igm/bin/activate Install IGM For simple usage, you can install the latest IGM stable version and its dependencies from the Pypi as follows: pip install igm_model OR for using all and recent features, you can install the IGM development version from the github repository as follows: git clone https://github.com/jouvetg/igm.git cd igm pip install -e . After that, you may run any example ( igm_run ). As IGM is being updated often, make sure you have the latest version, you may run git pull","title":"Linux"},{"location":"1.-Installation/#windows","text":"Tensorflow does not allow us to run IGM on GPU directly on Windows, and the module oggm_shop does not work on windows. Therefore, we recommend windows-user to install WSL2-ubuntu, which provides a linux/ubuntu terminal. WSL2 terminal can be nicely linked with VS code (with an extension). First, install WSL2-ubuntu wsl --install Ubuntu-22.04 sudo apt update sudo apt upgrade and then, install the NVIDIA drivers if not done (if you get no output from nvidia-smi ), and if you wish to use the GPU. The rest -- installation of conda or venv environment and the installation of IGM -- are the same as above on Linux.","title":"Windows"},{"location":"1.-Installation/#mac","text":"IGM core library native Tensorflow is not supported on Mac for GPU usage. Instead, a \"Tensorflow for Mac\", called tensorflow-metal , was developed as workaround. To install IGM on Mac, you may follow the linux workflow, however, you will need to change in setup.py tensorflow by tensorflow-macos. Here is a working procedure (tested on MacBook Pro M2) -- still we recommend using a virtual environment such as conda or venv as on linux: git clone -b develop https://github.com/jouvetg/igm cd igm You need to edit \"install_requires=[...]\" in the file \"setup.py\": To use only the CPUs: tensorflow-macos==2.14.0 To use the GPUs: tensorflow-macos==2.14.0, tensorflow-metal, and then pip install -e .","title":"Mac"},{"location":"1.-Installation/#troubleshooting","text":"Main source of issues are linked to Tensorflow and the use of GPU. Hopefully, the installation is significantly easier since tensorflow 2.14.0 since it can install all necessary GPU/cuda dependent packages with the right version automatically. Note that to ensure smooth usage of GPU with cuda and tensorflow libraries , one has to make sure that i) cuda ii) cudnn iii) tensorflow are compatible , and your Nvidia driver is compatible with the version of cuda. Such incompatibility is the most common source of issue. For instance, it is possible do install tensorflow-2.12.0 by setting tensorflow==2.12.0 in the setup.py and conda install -c conda-forge cudatoolkit=11.8.0 pip install nvidia-cudnn-cu11==8.6.0.163 mkdir -p ${CONDA_PREFIX}/etc/conda/activate.d D=${CONDA_PREFIX}/etc/conda/activate.d/env.sh echo 'export PYTHONNOUSERSITE=1' >> $D echo 'export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${CONDA_PREFIX}/lib' >> $D echo 'export CUDNN_PATH=$(dirname $(python -c \"import nvidia.cudnn;print(nvidia.cudnn.__file__)\"))' >> $D echo 'export LD_LIBRARY_PATH=$CONDA_PREFIX/lib/:$CUDNN_PATH/lib:$LD_LIBRARY_PATH' >> $D","title":"Troubleshooting"},{"location":"2.-Examples--%28quick-start%29/","text":"The best and quickest way to get to know IGM is to run given examples. Having IGM installed on your machine, you can simply run igm_run in a folder that contains the following parameter file params.json : { \"modules_preproc\": [\"oggm_shop\"], \"modules_process\": [\"clim_oggm\", \"smb_oggm\", \"iceflow\", \"time\", \"thk\" ], \"modules_postproc\": [\"write_ncdf\", \"plot2d\", \"print_info\", \"print_comp\"], \"clim_oggm_clim_trend_array\": [ [\"time\", \"delta_temp\", \"prec_scal\"], [ 1900, 0.0, 1.0], [ 2020, 0.0, 1.0], [ 2100, 4.0, 1.0] ], \"oggm_RGI_ID\": \"RGI60-11.01450\", \"time_start\": 1800.0, \"time_end\": 2100.0, \"plt2d_live\": true, \"iflo_init_slidingco\": 0.25 } You may run other ready-to-use examples in the folder test/examples/ in the develop version, which contains input data and parameter files. To run the example, just go in each folder and run igm_run there. You have the following examples available: quick-demo provides a set-up to model any glacier given an RGI ID, with a OGGM-based climate forcing and SMB. quick-demo-mysmb is like quick-demo but wirh a own user-defined SMB module / parametrization. aletsch-basic provides a simple set-up for an advance-retreat simulation of the largest glacier of the European Alps -- Aletsch Glacier, Switzerland -- using a simple parametrization of the mass balance based on time-varying Equilibrium Line Altitudes (ELA). aletsch-1880-2100 gives the set-up to reproduce the simulations of the Great Aletsch Glacier (Switzerland) in the past and in the future based on the CH2018 climate scenarios and an accumulation/melt model. aletsch-invert and rhone-invert gives an example of data assimilation with IGM (Warning: inverse modelling requires tuning parameters for each glacier). rhone-invert is the most advanced/recent setting. paleo-alps consists of a simple set-up to run a paleo glacier model in the European Alps in paleo times with different catchments (lyon, ticino, rhine, linth glaciers) with IGM around the last glacial maximum (LGM, about 24 BP in the Alps). synthetic permits to make simple numerical experiments with simple synthetic bedrock topographies.","title":"Examples"},{"location":"3.-Runing-IGM/","text":"Assuming you have installed the right igm environment, the glacier evolution model IGM can be run via the command igm_run : define igm_run --RGI-ID RGI60-11.01450 --time_start 2023 --time_end 2100 where parameters are given in command line as above or in a file params.json (recommended) like { \"modules_preproc\": [\"oggm_shop\"], \"modules_process\": [\"smb_simple\",\"iceflow\",\"time\",\"thk\"], \"modules_postproc\": [\"write_ncdf\",\"plot2d\",\"print_info\",\"print_comp\"], \"oggm_RGI_ID\": \"RGI60-11.01238\", \"time_start\": 2023.0, \"time_end\": 2100.0 } and igm_run.py is a short python script located in the root directory that perform the following steps (check the code for more details): collect parameters into params object, including the ordered list of modules modules , define a state object that contains all the data (e.g. ice thickness), initialize all model components in turn, update all model components in turn within a time loop from start to end times, finalize all model components in turn. Therefore running IGM requires to define parameters params , which includes first-of-all the list of wished IGM modules. IGM can also take the parameter file as input as follows: igm_run --param_file params1.json Parameters ( params , full list ) IGM has a few core parameters: short long default help --param_file params.json Parameter file --modules_preproc [\"prepare_data\"] List of pre-processing modules --modules_process [\"iceflow\",\"time\",\"thk\"] List of processing modules --modules_postproc [\"write_ncdf\",\"print_info\"] List of post-processing modules --logging False Activate the logging and many other module-specific parameters, see the full list of parameters or the module documentation for the meaning and default values of the parameters of each module. Parameters passed in command line override those passed in the jon parameter file, which override the default IGM parameters. Modules ( modules ) IGM is organized module-wise. Each user must pick a sequence of existing pre-processing , processing , post-processing and/or user-made modules she/he wishes to have for her/his application (check at the module documentation . Each module implements all least 4 functions for module-specific parameter definition, initialization, update and finalization, which are called by igm_run . This section helps to chose the appropriate module. First one needs pre-processing modules : For modelling individual present-day glacier, the best is to use the OGGM-based prepare_data module, which take care of downloading all the gridded data appropriatly. In that case, the modules_preproc in the json parameter file look like: \"modules_preproc\": [\"oggm_shop\"], Alternatively to module oggm_shop , one may load the data directly NetCDF file (with module load_ncdf ), tif file (with module load_tif ) or from analytical formula for synthetic glacier tests ( synthetic ). Optionally the additional module optimize permits to do data assimilation seeking for ice thickness distribution, ice flow parameters that yield the best fit with data (e.g. surface ice speeds). In that case, the `modules_preproc in the json parameter file look like: \"modules_preproc\": [\"prepare_data\",\"optimize\"], Second one needs to define processing modules: The minimum to have as processing is the combination of ice flow (module iceflow ), ice thickness (module thk ), and time step (module time ): \"modules_process\": [\"iceflow\"\",\"time\",\"thk\"], However, it sounds reasonable to add at least a surface mass balance module (e.g. smb_simple ), and other components we like to have (e.g. computation of vertical velocity, particle trajectory, climate, enthalpy, ...) making sure to respect a logical order, i.e., \"modules_process\": [\"smb_simple\",\"iceflow\",\"time\",\"thk\",\"vert_flow\",\"particles\"], Then, one needs post-processing modules to output the results of the model, e.g. this line will permit to write model output in NetCDF files, make 2D plots, print basic informatinN (e.g. ice volume), and produce a nice 3D animation of the run at the end: \"modules_postproc\": [ \"write_ncdf\", \"plot2d\", \"print_info\", \"anim_mayavi\" ] Lastly, one often needs to customize the code for specific applications. This is easy to do so with IGM, e.g. for imposing own climate forcing, defining own surface mass balance, ... For that purpose, implement your module in a separate file my_mod.py, and add it to the workflow \"modules_process\": [\"smb_simple\",\"iceflow\",\"time\",\"thk\",\"my_mod\"], then, the module will be automatically loaded by igm_run when being executed.","title":"Runing-IGM"},{"location":"3.-Runing-IGM/#parameters-params-full-list","text":"IGM has a few core parameters: short long default help --param_file params.json Parameter file --modules_preproc [\"prepare_data\"] List of pre-processing modules --modules_process [\"iceflow\",\"time\",\"thk\"] List of processing modules --modules_postproc [\"write_ncdf\",\"print_info\"] List of post-processing modules --logging False Activate the logging and many other module-specific parameters, see the full list of parameters or the module documentation for the meaning and default values of the parameters of each module. Parameters passed in command line override those passed in the jon parameter file, which override the default IGM parameters.","title":"Parameters (params, full list)"},{"location":"3.-Runing-IGM/#modules-modules","text":"IGM is organized module-wise. Each user must pick a sequence of existing pre-processing , processing , post-processing and/or user-made modules she/he wishes to have for her/his application (check at the module documentation . Each module implements all least 4 functions for module-specific parameter definition, initialization, update and finalization, which are called by igm_run . This section helps to chose the appropriate module. First one needs pre-processing modules : For modelling individual present-day glacier, the best is to use the OGGM-based prepare_data module, which take care of downloading all the gridded data appropriatly. In that case, the modules_preproc in the json parameter file look like: \"modules_preproc\": [\"oggm_shop\"], Alternatively to module oggm_shop , one may load the data directly NetCDF file (with module load_ncdf ), tif file (with module load_tif ) or from analytical formula for synthetic glacier tests ( synthetic ). Optionally the additional module optimize permits to do data assimilation seeking for ice thickness distribution, ice flow parameters that yield the best fit with data (e.g. surface ice speeds). In that case, the `modules_preproc in the json parameter file look like: \"modules_preproc\": [\"prepare_data\",\"optimize\"], Second one needs to define processing modules: The minimum to have as processing is the combination of ice flow (module iceflow ), ice thickness (module thk ), and time step (module time ): \"modules_process\": [\"iceflow\"\",\"time\",\"thk\"], However, it sounds reasonable to add at least a surface mass balance module (e.g. smb_simple ), and other components we like to have (e.g. computation of vertical velocity, particle trajectory, climate, enthalpy, ...) making sure to respect a logical order, i.e., \"modules_process\": [\"smb_simple\",\"iceflow\",\"time\",\"thk\",\"vert_flow\",\"particles\"], Then, one needs post-processing modules to output the results of the model, e.g. this line will permit to write model output in NetCDF files, make 2D plots, print basic informatinN (e.g. ice volume), and produce a nice 3D animation of the run at the end: \"modules_postproc\": [ \"write_ncdf\", \"plot2d\", \"print_info\", \"anim_mayavi\" ] Lastly, one often needs to customize the code for specific applications. This is easy to do so with IGM, e.g. for imposing own climate forcing, defining own surface mass balance, ... For that purpose, implement your module in a separate file my_mod.py, and add it to the workflow \"modules_process\": [\"smb_simple\",\"iceflow\",\"time\",\"thk\",\"my_mod\"], then, the module will be automatically loaded by igm_run when being executed.","title":"Modules (modules)"},{"location":"4.-IGM-module-documentation/","text":"Pre-processing modules Source code can be found in 'igm/modules/preproc' Module name Doc Code Description oggm_shop doc code feeds the initial 'state' from online data using OGGM given RGI ID (unix and mac only) load_ncdf doc code feeds the initial 'state' from a given NetCDF file load_tif doc code feeds the initial 'state' from given tiff files include_icemask doc code loads a shapefile (ESRI shapefile) and creates an ice mask from it pretraining doc code perform a pretraining of the iceflow emulator on a glacier catalogue optimize doc code perform the preliminary optimization/inversion scheme (e.g. find the bedrock) from observations Processing modules Source code can be found in 'igm/modules/process' Module name Doc Code Description clim_oggm doc code compute \"oggm-like\" climate data smb_oggm doc code compute \"oggm-like\" surface mass balance from climate data smb_simple doc code compute surface mass balance with a simple ELA parametrization iceflow doc code compute the horizontal iceflow velocity field using Physics-Informed Deep Learning time doc code compute the time step, time accounting for CFL and saving times thk doc code computes the ice thickness solving mass conservation equation vert_flow doc code compute the vertical component of the velocity a posteriori enthalpy doc code compute the enthalpy and the subglacial hydrology (new! use with care) particles doc code compute the trajectory of individual lagrangian particles rockflow doc code extend the velocity field in ice ice-free area to mimic the dynamics of rocks in steep terrain glerosion doc code update the topography after being eroded by glaciers avalanche doc code redistribute snow after taking into account snow avalanches gflex doc code Compute lithospheric flexure using gflex python module Post-processing modules Source code can be found in 'igm/modules/postproc' Module name Doc Code Description write_ncdf doc code writes the 2D results at given intervals in a NetCDF file write_tif doc code writes the 2D results at given intervals in a tif file write_ts doc code writes the time serie results at given intervals in a NetCDF file plot2d doc code produce on the fly 2D plots of ice thk/speed with particles if activated write_particles doc code write particle positions in dedicated files in the folder 'trajectory' print_info doc code write basic information on the fly about ice volume, time step ... print_comp doc code summarize the computational costs of each step, and global of the run at the end anim_plotly doc code interactively make 3D vizu from the final NetCDF file (depends on dash and plotly) anim_mayavi doc code make a nice 3D vizu from the final NetCDF file (depends on mayavi and pyqt5) anim_video doc code make a nice mp4 animation from the final NetCDF file","title":"IGM-module-documentation"},{"location":"4.-IGM-module-documentation/#pre-processing-modules","text":"Source code can be found in 'igm/modules/preproc' Module name Doc Code Description oggm_shop doc code feeds the initial 'state' from online data using OGGM given RGI ID (unix and mac only) load_ncdf doc code feeds the initial 'state' from a given NetCDF file load_tif doc code feeds the initial 'state' from given tiff files include_icemask doc code loads a shapefile (ESRI shapefile) and creates an ice mask from it pretraining doc code perform a pretraining of the iceflow emulator on a glacier catalogue optimize doc code perform the preliminary optimization/inversion scheme (e.g. find the bedrock) from observations","title":"Pre-processing modules"},{"location":"4.-IGM-module-documentation/#processing-modules","text":"Source code can be found in 'igm/modules/process' Module name Doc Code Description clim_oggm doc code compute \"oggm-like\" climate data smb_oggm doc code compute \"oggm-like\" surface mass balance from climate data smb_simple doc code compute surface mass balance with a simple ELA parametrization iceflow doc code compute the horizontal iceflow velocity field using Physics-Informed Deep Learning time doc code compute the time step, time accounting for CFL and saving times thk doc code computes the ice thickness solving mass conservation equation vert_flow doc code compute the vertical component of the velocity a posteriori enthalpy doc code compute the enthalpy and the subglacial hydrology (new! use with care) particles doc code compute the trajectory of individual lagrangian particles rockflow doc code extend the velocity field in ice ice-free area to mimic the dynamics of rocks in steep terrain glerosion doc code update the topography after being eroded by glaciers avalanche doc code redistribute snow after taking into account snow avalanches gflex doc code Compute lithospheric flexure using gflex python module","title":"Processing modules"},{"location":"4.-IGM-module-documentation/#post-processing-modules","text":"Source code can be found in 'igm/modules/postproc' Module name Doc Code Description write_ncdf doc code writes the 2D results at given intervals in a NetCDF file write_tif doc code writes the 2D results at given intervals in a tif file write_ts doc code writes the time serie results at given intervals in a NetCDF file plot2d doc code produce on the fly 2D plots of ice thk/speed with particles if activated write_particles doc code write particle positions in dedicated files in the folder 'trajectory' print_info doc code write basic information on the fly about ice volume, time step ... print_comp doc code summarize the computational costs of each step, and global of the run at the end anim_plotly doc code interactively make 3D vizu from the final NetCDF file (depends on dash and plotly) anim_mayavi doc code make a nice 3D vizu from the final NetCDF file (depends on mayavi and pyqt5) anim_video doc code make a nice mp4 animation from the final NetCDF file","title":"Post-processing modules"},{"location":"5.-Custom-modules-%28coding%29/","text":"It is fairly simple to write your own module in a separate python file and include it in the workflow, e.g. to force a climate and/or surface mass balance model specific to an application. For that, one needs to undestand how IGM is coded. Coding structure A closer look at script igm_run.py reveals the following main steps: Load key libraries (tensorflow and igm): Collect defaults, overide from json file, and parse all core and specific module parameters into params , load custom modules, and get the list of all modules in order: Define a state class/dictionnary that contains all the data (e.g. ice thickness) Initialize, update and finalize all model components in given order after placing on '/CPU:0' or '/GPU:0' device. Each module have at least 4 functions defined (some may do nothing, but still need to be defined): a parameter function 'params(parser)' that defines the parameter associated with the module, an initialization function 'initialize(params,state)' that initializes all that needs to be prior to the main time loop, an update function 'update(parser)' that updates the state within the main time loop, a finalize function 'finalize(parser)' that finalizes the module after the time loop. In igm_run , all variables describing the glacier state at a time t are stored in the state object. All these variable are TensorFlow 2.0 Tensors. Using Tensorflow is key to making computationally efficient operations, especially on GPU. Any variables can be accessed/modified via state.nameofthevariable, e.g., ```python state.thk # is the ice thickness variable state.usurf # is the top surface elevation Variables names are summarized [here](https://github.com/jouvetg/igm/wiki/5.-Variables). # Creating own module Similarly to existing IGM ones, a user-defined module my_module can be implemented in a file my_module.py, which will be will automatically loaded when `igm_run` is executed providing `my_module` is listed in any module list parameters. The implementation must have the 4 functions that permits to defined parameters, initializing, updating, and finalizing. For instance, to implementation of the mass balance function 'sinus' with an oscillating ELA, you may create a module 'mysmb' in a file mysmb.py, which update the object state.smb from other fields and parameters: ```python def params(parser): parser.add_argument(\"--meanela\", type=float, default=3000 ) def initialize(params,state): pass def update(params,state): # perturabe the ELA with sinusional signal ELA = ( params.meanela + 750*math.sin((state.t/100)*math.pi) ) # compute smb linear with elevation with 2 acc & abl gradients state.smb = state.usurf - ELA state.smb *= tf.where(state.smb<0, 0.005, 0.009) # cap smb by 2 m/y state.smb = tf.clip_by_value(state.smb, -100, 2) # make sure the smb is not positive outside of the mask to prevent overflow state.smb = tf.where((state.smb<0)|(state.icemask>0.5),state.smb,-10) def finalize(params,state): pass then, it remains to call these new function and add 'mysmb' to the list of modules as parameter. Note that the four functions (params, init, update, finalize) must be defined even if some are not doing anything (just use pass ). You may find coding inspiration / examples looking at the code of IGM modules above. IGM fully relies on TensorFlow 2.0 library for computational efficiency on GPU. All variables (e.g. ice thickness) are TensorFlow tensor objects, which can only be modified using TensorFlow operations. All these operations are vectorial , i.e. they apply simultaneously to all entries of 2D gridded fields, which is key for parallel and efficient execution. This means that one must avoid any sequential operations (typically loop of indices of 2D arrays), and favour TensorFlow (optimized) operations between large arrays (e.g. neural networks). At first sight, a lot of TensorFlow functions look similar to Numpy ones, one can simply do operations by changing numpy to tensorflow, e.g. 'tf.zeros()' instead of 'np.zeros()' with 'import tensorflow as tf' instead of 'import numpy as np'. E.g. Tensorflow operations look like: state.topg = tf.zeros_like(state.usurf) # define Variable Tensor state.smb = tf.where(state.usurf > 4000, 0, state.smb) # Imposes zero mass balance above 4000 m asl. state.usurf = state.topg + state.thk # Update surface topography with new ice thickness state.smb = tf.clip_by_value( (state.usurf - ela)*grad , -100, 2.0 ) # Define linear smb wrt z, with capping value u = tf.concat( [u[:, 0:1], 0.5 * (u[:, :-1] + u[:, 1:]), u[:, -1:]], 1 ) # work on straggered grid In fact, there are two kinds of tensor that are used in IGM. First, \"EagerTensor\" (as shown above) can make many operations, however, we can NOT change specific tensor entries (slicing): tensor = tf.ones((500,300)) tensor = (2*tensor + 200)**2 tensor[1,2] = 5 # WILL NOT WORK As a workaround, one uses \"tf.Variable\" that permits to slice, however, the assignment is slightly different, it can not be done with \"=\", but with the \"assign\" function: tensor = tf.Variable(tf.ones((500,300))) tensor.assign( (2*tensor + 200)**2 ) tensor[1,2].assign( 5 ) # WORKS ! IGM combines both types of tensors, so make sure to identify what is your type, other TF will produce an error. For the best computational efficiency, it is crucial to keep all variables and operations within the TensorFlow framework without using Numpy (to avoid unnecessary transfers between GPU and CPU memory). There is the possibility to generate TensorFlow function using Numpy code, check at this page . The best way to learn how to code with tensorflow within the context of IGM is to explore module codes , or to look at examples . Overriding modules Sometime, it may happen that you would like to bring a minor modification to an existing module. If so, no need to copy/paste the entire module and bring your modification, you may simply define a module with the same name existingmodule.py that contains only the function you would like to modify. All other function will be taken from the orginal module. For instance, this IGM example implements a special seeding strategy for the particle module in user-defined particles.py. Only two functions of the module are changed. Sharing your module If you have developed a module that you believe may be useful to the community and be shared within igm package, read this section carefully. First, give a meaningful name to your module, and try to match the structure of other existing modules for consistency. Please name modulename.py and modulename.md the python and the documentation files, respectively. The parameter list coming at the end of modulename.md in the doc folder will be generated automatically, so you don't need to do it yourself. Please make sure to name all parameters of your module with a 4 letter long keyword that shorten the name of your module. This permits to prevent against conflicts between parameter names of different modules. Once all of this is achieve, you may contact me, or do a pull request.","title":"Custom-modules"},{"location":"5.-Custom-modules-%28coding%29/#coding-structure","text":"A closer look at script igm_run.py reveals the following main steps: Load key libraries (tensorflow and igm): Collect defaults, overide from json file, and parse all core and specific module parameters into params , load custom modules, and get the list of all modules in order: Define a state class/dictionnary that contains all the data (e.g. ice thickness) Initialize, update and finalize all model components in given order after placing on '/CPU:0' or '/GPU:0' device. Each module have at least 4 functions defined (some may do nothing, but still need to be defined): a parameter function 'params(parser)' that defines the parameter associated with the module, an initialization function 'initialize(params,state)' that initializes all that needs to be prior to the main time loop, an update function 'update(parser)' that updates the state within the main time loop, a finalize function 'finalize(parser)' that finalizes the module after the time loop. In igm_run , all variables describing the glacier state at a time t are stored in the state object. All these variable are TensorFlow 2.0 Tensors. Using Tensorflow is key to making computationally efficient operations, especially on GPU. Any variables can be accessed/modified via state.nameofthevariable, e.g., ```python state.thk # is the ice thickness variable state.usurf # is the top surface elevation Variables names are summarized [here](https://github.com/jouvetg/igm/wiki/5.-Variables). # Creating own module Similarly to existing IGM ones, a user-defined module my_module can be implemented in a file my_module.py, which will be will automatically loaded when `igm_run` is executed providing `my_module` is listed in any module list parameters. The implementation must have the 4 functions that permits to defined parameters, initializing, updating, and finalizing. For instance, to implementation of the mass balance function 'sinus' with an oscillating ELA, you may create a module 'mysmb' in a file mysmb.py, which update the object state.smb from other fields and parameters: ```python def params(parser): parser.add_argument(\"--meanela\", type=float, default=3000 ) def initialize(params,state): pass def update(params,state): # perturabe the ELA with sinusional signal ELA = ( params.meanela + 750*math.sin((state.t/100)*math.pi) ) # compute smb linear with elevation with 2 acc & abl gradients state.smb = state.usurf - ELA state.smb *= tf.where(state.smb<0, 0.005, 0.009) # cap smb by 2 m/y state.smb = tf.clip_by_value(state.smb, -100, 2) # make sure the smb is not positive outside of the mask to prevent overflow state.smb = tf.where((state.smb<0)|(state.icemask>0.5),state.smb,-10) def finalize(params,state): pass then, it remains to call these new function and add 'mysmb' to the list of modules as parameter. Note that the four functions (params, init, update, finalize) must be defined even if some are not doing anything (just use pass ). You may find coding inspiration / examples looking at the code of IGM modules above. IGM fully relies on TensorFlow 2.0 library for computational efficiency on GPU. All variables (e.g. ice thickness) are TensorFlow tensor objects, which can only be modified using TensorFlow operations. All these operations are vectorial , i.e. they apply simultaneously to all entries of 2D gridded fields, which is key for parallel and efficient execution. This means that one must avoid any sequential operations (typically loop of indices of 2D arrays), and favour TensorFlow (optimized) operations between large arrays (e.g. neural networks). At first sight, a lot of TensorFlow functions look similar to Numpy ones, one can simply do operations by changing numpy to tensorflow, e.g. 'tf.zeros()' instead of 'np.zeros()' with 'import tensorflow as tf' instead of 'import numpy as np'. E.g. Tensorflow operations look like: state.topg = tf.zeros_like(state.usurf) # define Variable Tensor state.smb = tf.where(state.usurf > 4000, 0, state.smb) # Imposes zero mass balance above 4000 m asl. state.usurf = state.topg + state.thk # Update surface topography with new ice thickness state.smb = tf.clip_by_value( (state.usurf - ela)*grad , -100, 2.0 ) # Define linear smb wrt z, with capping value u = tf.concat( [u[:, 0:1], 0.5 * (u[:, :-1] + u[:, 1:]), u[:, -1:]], 1 ) # work on straggered grid In fact, there are two kinds of tensor that are used in IGM. First, \"EagerTensor\" (as shown above) can make many operations, however, we can NOT change specific tensor entries (slicing): tensor = tf.ones((500,300)) tensor = (2*tensor + 200)**2 tensor[1,2] = 5 # WILL NOT WORK As a workaround, one uses \"tf.Variable\" that permits to slice, however, the assignment is slightly different, it can not be done with \"=\", but with the \"assign\" function: tensor = tf.Variable(tf.ones((500,300))) tensor.assign( (2*tensor + 200)**2 ) tensor[1,2].assign( 5 ) # WORKS ! IGM combines both types of tensors, so make sure to identify what is your type, other TF will produce an error. For the best computational efficiency, it is crucial to keep all variables and operations within the TensorFlow framework without using Numpy (to avoid unnecessary transfers between GPU and CPU memory). There is the possibility to generate TensorFlow function using Numpy code, check at this page . The best way to learn how to code with tensorflow within the context of IGM is to explore module codes , or to look at examples .","title":"Coding structure"},{"location":"5.-Custom-modules-%28coding%29/#overriding-modules","text":"Sometime, it may happen that you would like to bring a minor modification to an existing module. If so, no need to copy/paste the entire module and bring your modification, you may simply define a module with the same name existingmodule.py that contains only the function you would like to modify. All other function will be taken from the orginal module. For instance, this IGM example implements a special seeding strategy for the particle module in user-defined particles.py. Only two functions of the module are changed.","title":"Overriding modules"},{"location":"5.-Custom-modules-%28coding%29/#sharing-your-module","text":"If you have developed a module that you believe may be useful to the community and be shared within igm package, read this section carefully. First, give a meaningful name to your module, and try to match the structure of other existing modules for consistency. Please name modulename.py and modulename.md the python and the documentation files, respectively. The parameter list coming at the end of modulename.md in the doc folder will be generated automatically, so you don't need to do it yourself. Please make sure to name all parameters of your module with a 4 letter long keyword that shorten the name of your module. This permits to prevent against conflicts between parameter names of different modules. Once all of this is achieve, you may contact me, or do a pull request.","title":"Sharing your module"},{"location":"6.-Variables/","text":"Whenever this is possible, IGM adopts name convention of PISM . Here is a minimal list of key variables: Variable names Shape Description Unit t () Time variable (scalar) y dt () Time step (scalar) y x,y (nx) Coordinates vectors m thk (ny) Ice thickness m topg (ny,nx) Basal topography (or bedrock) m usurf (ny,nx) Surface topography m smb (ny,nx) Surface Mass Balance m/y ice-eq ubar (ny,nx) x- depth-average velocity of ice m/y vbar (ny,nx) y- depth-average velocity of ice m/y U (nz,ny,nx) x-horiz. 3D velocity field of ice m/y V (nz,ny,nx) y-horiz. 3D velocity field of ice m/y W (nz,ny,nx) z-vert. 3D velocity field of ice m/y arrhenius (ny,nx) Arrhenius Factor MPa^(-3) y^(-1) slidingco (ny,nx) Sliding Coefficient MPa m^(-1/3) y^(-1/3) divflux (ny,nx) Divergence of the flux m/y icemask (ny,nx) Mask to restrict the smb comp. - dtopgdt (ny,nx) Erosion rate m/y xpos,ypos (nb particles) x,y position of particles m rhpos (nb particles) rel. pos of particles in ice column m air_temp (nt,ny,nx) seasonal air temperature 2 m above ground \u00b0C precipitation (nt,ny,nx) seasonal precipitation (water eq) kg m^(-2) y^(-1)","title":"Variables"},{"location":"About-GPUs/","text":"IGM works fine on CPU for small computational domains (typically individual glaciers). In contrast, GPUs will be very advantageous to treat very large computational grids (typically large networks of glaciers) as IGM naturally takes further benefit from parallelism. Resolution Minimum computational ressource 0.25 K: 256 x 192 pixel CPU 1 K : 1024 x 768 pixel laptop GPU e.g., RTX A4000 4 K : 3840 x 2160 pixel excellent GPU e.g., RTX 4090 To illustrate this, I modeled the ice dynamics and glacier evolution over New Zealand by forcing the mass balance with an ELA oscillating between 1000 and 2000 meters a.s.l. The 1000-year-long simulation took about 1.5 hours on the Nvidia RTX 3090 GPU with a 640x700 km computational domain at 200 meters of resolution (i.e. 3200x3500 grid). The animation can be visualized on this link .","title":"About GPUs"},{"location":"Credits-and-references/","text":"References There is currently an in-progress IGM technical paper that will give you an overview of the physical components, modules, and capabilities of IGM. If you use IGM in publications, make sure to cite one of the following papers and the code version you used. @article{IGM, author = \"Jouvet, Guillaume and Cordonnier, Guillaume and Kim, Byungsoo and L\u00fcthi, Martin and Vieli, Andreas and Aschwanden, Andy\", title = \"Deep learning speeds up ice flow modelling by several orders of magnitude\", DOI = \"10.1017/jog.2021.120\", journal = \"Journal of Glaciology\", year = 2021, pages = \"1\u201314\", publisher = \"Cambridge University Press\" } @article{IGM-inv, author = \"Jouvet, Guillaume\", title = \"Inversion of a Stokes ice flow model emulated by deep learning\", DOI = \"10.1017/jog.2022.41\", journal = \"Journal of Glaciology\", year = \"2022\", pages = \"1--14\", publisher = \"Cambridge University Press\" } @article{IGM-PINN, title={Ice-flow model emulator based on physics-informed deep learning}, author={Jouvet, Guillaume and Cordonnier, Guillaume}, journal={Journal of Glaciology}, pages={1--15}, year={2023}, publisher={Cambridge University Press}, doi={10.1017/jog.2023.73} } Acknowledgements I greatly thank Guillaume Cordonnier for his valuable help with the TensorFlow implementation. The Parallel Ice Sheet Model has greatly inspired the naming of variables, as well as the format of input and output NetCDF files.","title":"References"},{"location":"Credits-and-references/#references","text":"There is currently an in-progress IGM technical paper that will give you an overview of the physical components, modules, and capabilities of IGM. If you use IGM in publications, make sure to cite one of the following papers and the code version you used. @article{IGM, author = \"Jouvet, Guillaume and Cordonnier, Guillaume and Kim, Byungsoo and L\u00fcthi, Martin and Vieli, Andreas and Aschwanden, Andy\", title = \"Deep learning speeds up ice flow modelling by several orders of magnitude\", DOI = \"10.1017/jog.2021.120\", journal = \"Journal of Glaciology\", year = 2021, pages = \"1\u201314\", publisher = \"Cambridge University Press\" } @article{IGM-inv, author = \"Jouvet, Guillaume\", title = \"Inversion of a Stokes ice flow model emulated by deep learning\", DOI = \"10.1017/jog.2022.41\", journal = \"Journal of Glaciology\", year = \"2022\", pages = \"1--14\", publisher = \"Cambridge University Press\" } @article{IGM-PINN, title={Ice-flow model emulator based on physics-informed deep learning}, author={Jouvet, Guillaume and Cordonnier, Guillaume}, journal={Journal of Glaciology}, pages={1--15}, year={2023}, publisher={Cambridge University Press}, doi={10.1017/jog.2023.73} }","title":"References"},{"location":"Credits-and-references/#acknowledgements","text":"I greatly thank Guillaume Cordonnier for his valuable help with the TensorFlow implementation. The Parallel Ice Sheet Model has greatly inspired the naming of variables, as well as the format of input and output NetCDF files.","title":"Acknowledgements"},{"location":"Home/","text":"Before to start If you don't know anything about glacier processes, explore this great website . If you don't know anything about glacier evolution modeling, you may watch first this video , which gives some basics. OS: IGM was developed in a Linux environment but works on Windows and Mac. Windows user are strongly recommended to use WSL2 for using the GPU and the OGGM shop module. Disclaimer: IGM implements empirical physical laws, with an important amount of approximations (of any kind). Make sure to understand what you do, to explore key parameters, and interpret the results with care. How to start Running IGM consists of running a python script igm_run , which is made of functions of the IGM python package. This documentation will help you to understand the parameters and, set-up your model by listing the modules you need, customize your own modules for your application. First, start with the 10-min video tutorial , or a longer IGS seminar presentation , and/or look at the in-progress IGM technical paper . Then, install an igm python environment on your system and starting with examples . Then, learn how to run IGM with module list and parameter setting (without extra coding), and explore the module documentation . Last, understand the code and write your own module code .","title":"Before to start"},{"location":"Home/#before-to-start","text":"If you don't know anything about glacier processes, explore this great website . If you don't know anything about glacier evolution modeling, you may watch first this video , which gives some basics. OS: IGM was developed in a Linux environment but works on Windows and Mac. Windows user are strongly recommended to use WSL2 for using the GPU and the OGGM shop module. Disclaimer: IGM implements empirical physical laws, with an important amount of approximations (of any kind). Make sure to understand what you do, to explore key parameters, and interpret the results with care.","title":"Before to start"},{"location":"Home/#how-to-start","text":"Running IGM consists of running a python script igm_run , which is made of functions of the IGM python package. This documentation will help you to understand the parameters and, set-up your model by listing the modules you need, customize your own modules for your application. First, start with the 10-min video tutorial , or a longer IGS seminar presentation , and/or look at the in-progress IGM technical paper . Then, install an igm python environment on your system and starting with examples . Then, learn how to run IGM with module list and parameter setting (without extra coding), and explore the module documentation . Last, understand the code and write your own module code .","title":"How to start"},{"location":"Q%26A/","text":"Ice is stuck on the border of the domain (no fluxes), what can I do? Set parameter exclude_borders_from_iceflow to True I see some numerical artifacts (e.g. waves) occurring when modeling glacier evolution, what can I do? Reduce the CFL parameter How to create/modify NetCDF files? There are many ways to prepare NetCDF files (matlab, python, GIS tools, ...). The NCO toolkit permits easy operations in command lines, e.g. ncks -x -v thk file.nc file.nc # this removes the variable 'thk' from file.nc ncks -v usurf file.nc file.nc # this extracts the variable usurf from file.nc ncap2 -h -O -s 'thk=0*thk' file.nc file.nc # this does operations on file.nc, here force zero thk ncrename -v apc,strflowctrl file.nc # this renames varible apc to strflowctrl in file.nc oggm_shop produces error on windows This is expected, OGGM is not supported on windows, however, modifying the tarfile.py file at line 2677 from name == member_name to name.replace(os.sep, '/') == member_name seems to fix the issue on Windows. Thanks Alexi Morin for proposing this workaround.","title":"Q&A"}]}